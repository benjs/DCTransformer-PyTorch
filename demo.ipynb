{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39164bitvenvvenvf2c9b4834eef47e697adcf97600cf570",
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/benjs/DCTransformer-PyTorch.git dctransformer_demo\n",
    "%cd dctransformer_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dctransformer.transforms import DCTCompression\n",
    "dct = DCTCompression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "weights = (dct.weight+1)/2 # from (-1,1) to (0,1)\n",
    "im_grid = torchvision.utils.make_grid(weights, nrow=8, padding=1)\n",
    "plt.imshow(im_grid.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCT transform should yield high values at position 1 and 2 \n",
    "# (not 1 and 8 because of zigzag ordering)\n",
    "img = (weights[1] + weights[8])/2\n",
    "img = (img+1)/2 * 255\n",
    "\n",
    "plt.imshow(img.permute(1,2,0), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = img.unsqueeze(0).repeat(1,3,1,1) # Need batched and 3 channels\n",
    "img3 = (img3+1)/2 * 255\n",
    "torch.round(dct(img3)).view(192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}